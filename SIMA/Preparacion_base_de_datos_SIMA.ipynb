{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XARUTMN-xPnN"
      },
      "source": [
        "# Desarrollo y exploracion de las bases de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89zwKBbCxaSj"
      },
      "source": [
        "Link a la carpeta donde se está trabajando:\n",
        "https://drive.google.com/drive/folders/1T2RLe3RsoYE_DBRdEyJCqbEXx4lDr44A?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZqKYL6Cvhpm",
        "outputId": "34cf12c9-37a4-405b-d8ee-dab651955d00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting fancyimpute\n",
            "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting knnimpute>=0.1.0 (from fancyimpute)\n",
            "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.5.2)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.5.3)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (7.4.4)\n",
            "Collecting nose (from fancyimpute)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (3.5.0)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (0.6.7.post0)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (2.0.14)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (0.9.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (3.2.7)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.6.2->cvxpy->fancyimpute) (0.1.7.post4)\n",
            "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fancyimpute, knnimpute\n",
            "  Building wheel for fancyimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29880 sha256=81b019ea331bab0949cab5368fcbcd75db58d68e160a1b287fb0c6102435d51f\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/0c/d3/ee82d1fbdcc0858d96434af108608d01703505d453720c84ed\n",
            "  Building wheel for knnimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11330 sha256=04969989c9699a1341bed1247e4fc4aecc23139b86458a309ae6bfbf312023ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/06/a5/45a724630562413c374e29c08732411d496092408b3a7bf754\n",
            "Successfully built fancyimpute knnimpute\n",
            "Installing collected packages: nose, knnimpute, fancyimpute\n",
            "Successfully installed fancyimpute-0.7.0 knnimpute-0.1.0 nose-1.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install fancyimpute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xsnh-EQexly4"
      },
      "source": [
        "## 0. Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq4rgiuAXe9U",
        "outputId": "616dcaa9-afe0-42f9-920b-5eeac9c68db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYQwm8olfH38"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVyovO63YHnT"
      },
      "source": [
        "### 0.1. Preparacion base de datos 2023-2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-mkviW7xxGp"
      },
      "source": [
        "#### 0.1.1. Generalización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR4-_zKmx0yp"
      },
      "source": [
        "**¿Qué se hizo?**\n",
        "\\\n",
        "\\\n",
        "A partir de las bases de datos otorgadas, se escogieron 3 para el desarrollo del proyecto.\n",
        "- Datos historicos 2020-2021\n",
        "- Datos historicos 2022-2023\n",
        "- Datos historicos 2023-2024\n",
        "\n",
        "Las primeras dos bases de datos, están distribuidas de manera en el que se muestra la produccion por hora durante los años mencionados de los contaminantes que procesa cada estación, en el que cada hoja corresponde a una zona diferente.\n",
        "\n",
        "En este caso, de manera manual se decidió crear un archivo .csv, el cual es un archivo por zona, siguiendo el nombre de {zona}_añoinicial_añofinal.csv.\n",
        "\n",
        "Los datos historicos de 2023-2024 cuentan con una distribución diferente, en el que los datos de todas las zonas se encuentran presentes dentro de una misma hoja, al igual que ahora los encabezados son diferentes, donde en lugar de ser una sola fila con el nombre de la molecula, son tres filas, con el nombre de fila, nombre de la molecula y unidad de medición respectivamente.\n",
        "\n",
        "De manera un poco ineficiente, pero favoreciendo el entendimiento humano de los datos, se intentó separar de manera manual, sin embargo esto no fue posible debido a la magitud de la informacion encontrada en la misma hoja.\n",
        "Por ende se realizó el siguiente codigo, el cual, después de haber eliminado la columna de zona y unidad de medición d emanera manual, estandariza el formato de la información acual con la de años anteriores, al igual que se considera eficiente si se decide continuar con este formato en años futuros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL1oaQ9nYMFp"
      },
      "source": [
        "#### 0.1.2 Codigo de estandarización de formato en base de datos Datos Historicos 2023-2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlLLt24_l6Xc",
        "outputId": "95d591e5-d53b-4873-d656-69e5611cb0e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos generados correctamente.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ruta del archivo\n",
        "archivo_principal = '/content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/TODO/DATOS_HISTÓRICOS_2023_2024_TODAS_ESTACIONES_ITESM.csv'\n",
        "\n",
        "# Nombres de las zonas y sus respectivos archivos\n",
        "zonas = ['SURESTE', 'NORESTE', 'CENTRO', 'NOROESTE', 'SUROESTE', 'NOROESTE2', 'NORTE', 'NORESTE2', 'SURESTE2', 'SUROESTE2', 'SURESTE3', 'SUR', 'NORTE2', 'NORESTE3', 'NOROESTE3']\n",
        "\n",
        "# Columnas que tiene cada conjunto\n",
        "columnas_por_zona = ['CO', 'NO', 'NO2', 'NOX', 'O3', 'PM10', 'PM2.5', 'PRS', 'RAINF', 'RH', 'SO2', 'SR', 'TOUT', 'WSR', 'WDR']\n",
        "\n",
        "# Lee el archivo principal (usando low_memory=False y dtype=str para evitar advertencias)\n",
        "df = pd.read_csv(archivo_principal, header=0, index_col=False, low_memory=False, dtype=str)\n",
        "\n",
        "# Ubicación donde se guardarán los archivos\n",
        "ruta_guardado = '/content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/PROCESADO/2023_2024'\n",
        "\n",
        "# Procesa cada conjunto de columnas\n",
        "for i, zona in enumerate(zonas):\n",
        "    # Determina las columnas para esta zona (se asume que hay una columna vacía entre cada conjunto de datos)\n",
        "    inicio = i * (len(columnas_por_zona) + 1) + 1  # Se incluye la columna vacía como separación\n",
        "    fin = inicio + len(columnas_por_zona)\n",
        "\n",
        "    # Extrae la columna \"date\" y el conjunto de columnas para la zona\n",
        "    columnas_zona = ['date'] + list(df.columns[inicio:fin])\n",
        "\n",
        "    # Filtra el DataFrame por esas columnas\n",
        "    df_zona = df[columnas_zona]\n",
        "\n",
        "    # Renombra las columnas para que no incluyan los sufijos numéricos\n",
        "    df_zona.columns = ['date'] + columnas_por_zona\n",
        "\n",
        "    # Guarda el archivo CSV para cada zona\n",
        "    nombre_archivo = f\"{zona}_2023_2024.csv\"\n",
        "    df_zona.to_csv(ruta_guardado + nombre_archivo, index=False)\n",
        "\n",
        "print(\"Archivos generados correctamente.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXHanPIQZkyJ"
      },
      "source": [
        "### 0.2. Unión de archivos .csv por año"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0pt4zeO3jj_"
      },
      "source": [
        "Una vez compilado el código anterior, se tienen archivos .csv de cada partícula divididos por año, para contar con un codigo más eficiente, se decide unir todos los codigos en un solo archivo, el cual una los valores del 2020 al 2024.\n",
        "\n",
        "Es importante tomar en cuenta que este archivo solo une la información, pero los datos siguen sin procesar, es decir, todos los valores vacíos y nulos siguien presentes en los datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4aL6ouiZhuY",
        "outputId": "a7021976-3419-404a-ac0d-2f02de131265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-ce31e149fcb9>:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  combined_df = pd.concat(df_list, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos combinados y guardados en: /content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/PROCESADO/TODO/BASES_2020_2024_SP.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Rutas de las carpetas con archivos CSV\n",
        "folders = [\n",
        "    '/content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/PROCESADO/2020_2021/',\n",
        "    '/content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/PROCESADO/2022_2023/',\n",
        "    '/content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/PROCESADO/2023_2024/'\n",
        "]\n",
        "\n",
        "# Ruta de destino para el archivo combinado\n",
        "output_folder = '/content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/PROCESADO/TODO/'\n",
        "output_file = os.path.join(output_folder, 'BASES_2020_2024_SP.csv')\n",
        "\n",
        "# Crear una lista para almacenar los DataFrames\n",
        "df_list = []\n",
        "\n",
        "# Leer y concatenar los archivos CSV de cada carpeta\n",
        "for folder in folders:\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.endswith(\".csv\"):\n",
        "            file_path = os.path.join(folder, filename)\n",
        "            # Leer el archivo CSV\n",
        "            df = pd.read_csv(file_path)\n",
        "\n",
        "            # Extraer la zona del nombre del archivo\n",
        "            zona = filename.split('_')[0]  # Obtiene el primer segmento del nombre (por ejemplo, 'CENTRO')\n",
        "\n",
        "            # Agregar la nueva columna de zona al DataFrame\n",
        "            df['zona'] = zona\n",
        "\n",
        "            # Agregar el DataFrame a la lista\n",
        "            df_list.append(df)\n",
        "\n",
        "# Concatenar todos los DataFrames\n",
        "combined_df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# Guardar el archivo combinado en la nueva ubicación\n",
        "combined_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f'Archivos combinados y guardados en: {output_file}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0vy8Q0ZwqDj"
      },
      "source": [
        "## 1. Limpieza y Exploracion de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.0 REBOOT"
      ],
      "metadata": {
        "id": "PXqO-bNdeAQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [REBOOT]"
      ],
      "metadata": {
        "id": "ZPCCZyHOc388"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6dy7c-ocyZb",
        "outputId": "93e68a83-653f-4354-91e7-d1e8ae0eb51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "xl7ewJRcc1kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE2KZPC_qsqa",
        "outputId": "1156528b-ce8e-4fe8-8f2b-d13cfdad19f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-c242efa54de3>:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_2020_2024 = pd.read_csv('/content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/PROCESADO/TODO/BASES_2020_2024_SP.csv')\n"
          ]
        }
      ],
      "source": [
        "# Cargar los DataFrames\n",
        "df_2020_2024 = pd.read_csv('/content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/PROCESADO/TODO/BASES_2020_2024_SP.csv')\n",
        "df_UBI = pd.read_csv('/content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/PROCESADO/UBICACIONES/UBI.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWyB-fQx4__n"
      },
      "source": [
        "### 1.1. Limpieza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivZqGBxas_nL"
      },
      "source": [
        "#### 1.1.1 Asegurar formato punto decimal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr_N8Gz_tCil",
        "outputId": "29900db3-6cb8-4bd9-9392-32e2123fb5bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     CO   NO   NO2   NOX    O3    PM10  PM2.5    PRS  RAINF    RH  SO2     SR  \\\n",
            "0   NaN  NaN   NaN   NaN   NaN   86.34  60.91    NaN    NaN   NaN  NaN  0.000   \n",
            "1   NaN  NaN   6.5   9.8  19.0  112.01  85.64  713.6    0.0  91.0  NaN  0.158   \n",
            "2   NaN  NaN   5.6   8.8  18.0  100.01  72.39  712.8    0.0  91.0  NaN  0.156   \n",
            "3  3.22  3.2   7.2  10.4  14.0  106.20  70.25  712.4    0.0  92.0  2.9  0.158   \n",
            "4  3.26  4.7  10.6  15.3   5.0  141.86  93.72  712.0    0.0  92.0  3.3  0.163   \n",
            "\n",
            "    TOUT  WSR    WDR  \n",
            "0    NaN  NaN    NaN  \n",
            "1  10.49  3.7    2.0  \n",
            "2  10.51  1.9  144.0  \n",
            "3  10.64  2.7   28.0  \n",
            "4  10.73  2.0   31.0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Suponiendo que ya tienes tu dataframe df_2020_2024 cargado\n",
        "\n",
        "# Lista de columnas donde se debe reemplazar la coma por punto\n",
        "columnas_a_reemplazar = ['CO', 'NO', 'NO2', 'NOX', 'O3', 'PM10', 'PM2.5', 'PRS', 'RAINF', 'RH', 'SO2', 'SR', 'TOUT', 'WSR', 'WDR']\n",
        "\n",
        "# Reemplazar comas por puntos en las columnas seleccionadas\n",
        "df_2020_2024[columnas_a_reemplazar] = df_2020_2024[columnas_a_reemplazar].replace({',': '.'}, regex=True)\n",
        "\n",
        "# Convertir las columnas a tipo numérico\n",
        "df_2020_2024[columnas_a_reemplazar] = df_2020_2024[columnas_a_reemplazar].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Verificar los cambios\n",
        "print(df_2020_2024[columnas_a_reemplazar].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkKZMNDptJAi"
      },
      "source": [
        "#### 1.1.2. Separación de fecha y hora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhkYDFBctMw8",
        "outputId": "ebae3688-43f4-46e2-e5ed-7950c270184b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Las columnas 'date' y 'time' han sido separadas y los archivos guardados.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Función para dividir la columna 'date' en 'date' y 'time'\n",
        "def split_date_time(df):\n",
        "    # Convertir la columna 'date' a tipo datetime\n",
        "    df['date'] = pd.to_datetime(df['date'], format='%m/%d/%y %H:%M')\n",
        "\n",
        "    # Extraer la fecha y la hora en columnas separadas\n",
        "    df['time'] = df['date'].dt.time   # Extraer la hora\n",
        "    df['date'] = df['date'].dt.date   # Extraer la fecha\n",
        "\n",
        "    return df\n",
        "\n",
        "# Aplicar la función a cada DataFrame\n",
        "\n",
        "df_2020_2024 = split_date_time(df_2020_2024)\n",
        "\n",
        "# Guardar los DataFrames con las nuevas columnas\n",
        "\n",
        "#df_2020_2024.to_csv('/content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/PROCESADO/TODO/BASES_2020_2024_SP_mod.csv', index=False)\n",
        "\n",
        "print(\"Las columnas 'date' y 'time' han sido separadas y los archivos guardados.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDBe1FRFtTMh"
      },
      "source": [
        "#### 1.1.3. Encoding de las zonas"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yNOqHWTqgVi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSgW9FvqtWPb",
        "outputId": "83f82297-e4d2-4131-9dfa-621504acc4e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diccionario de encoding para 2020-2024: {'CENTRO': 0, 'NORESTE': 1, 'NORESTE2': 2, 'NORESTE3': 3, 'NOROESTE': 4, 'NOROESTE2': 5, 'NOROESTE3': 6, 'NORTE': 7, 'NORTE2': 8, 'SUR': 9, 'SURESTE': 10, 'SURESTE2': 11, 'SURESTE3': 12, 'SUROESTE': 13, 'SUROESTE2': 14}\n",
            "Los archivos con la columna 'Zona' eliminada han sido guardados.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Función para codificar la columna 'Zona' y generar el diccionario de encoding\n",
        "def encode_zona(df):\n",
        "    # Crear el codificador\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    # Ajustar el codificador a la columna 'Zona' y transformar los valores\n",
        "    df['zona_encoded'] = le.fit_transform(df['zona'])\n",
        "\n",
        "    # Crear el diccionario de encoding\n",
        "    zona_dict = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "\n",
        "    # Eliminar la columna 'Zona' original\n",
        "    df = df.drop(columns=['zona'])\n",
        "\n",
        "    return df, zona_dict\n",
        "\n",
        "# Aplicar la codificación a cada DataFrame\n",
        "df_2020_2024, zona_dict_2020_2024 = encode_zona(df_2020_2024)\n",
        "\n",
        "# Mostrar los diccionarios de encoding para cada DataFrame\n",
        "print(\"Diccionario de encoding para 2020-2024:\", zona_dict_2020_2024)\n",
        "\n",
        "# Guardar los DataFrames con la columna 'Zona' eliminada y la columna 'Zona_encoded'\n",
        "#df_2020_2024.to_csv('/content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/PROCESADO/TODO/BASES_2020_2024_SP_encoded.csv', index=False)\n",
        "\n",
        "print(\"Los archivos con la columna 'Zona' eliminada han sido guardados.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7tCJqfgthMd"
      },
      "source": [
        "#### 1.1.4. Asegurar propiedades numericas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIMFberUtkKe"
      },
      "outputs": [],
      "source": [
        "# Definir columnas relevantes para la imputación\n",
        "columnas_relevantes = ['CO', 'NO', 'NO2', 'NOX', 'O3', 'PM10', 'PM2.5', 'PRS', 'RAINF', 'RH', 'SO2', 'SR', 'TOUT', 'WSR', 'WDR']\n",
        "\n",
        "# Convertir solo las columnas relevantes a formato numérico\n",
        "df_2020_2024[columnas_relevantes] = df_2020_2024[columnas_relevantes].apply(pd.to_numeric, errors='coerce')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL80Zeuft4ec"
      },
      "source": [
        "### 1.2. Exploración"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlDM9AFE5II_"
      },
      "source": [
        "#### 1.2.1 Dimensión del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXjSIDyQrCuu",
        "outputId": "fdea6c7e-4b1b-4c21-cb7a-5f23e484217b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de registros: 659361\n",
            "Cantidad de columnas: 18\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Obtener la dimensión del dataset\n",
        "dim_dataset = df_2020_2024.shape\n",
        "print(\"Cantidad de registros:\", dim_dataset[0])\n",
        "print(\"Cantidad de columnas:\", dim_dataset[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMYn_KjM5LQN"
      },
      "source": [
        "#### 1.2.2. Cantidad de datos nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUy61_7G5PhM",
        "outputId": "36f2378a-c3bc-4495-cf16-1e429f9374e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cantidad de datos nulos por columna:\n",
            "CO        86861\n",
            "NO       113553\n",
            "NO2      118483\n",
            "NOX      114007\n",
            "O3       109258\n",
            "PM10      35980\n",
            "PM2.5    160358\n",
            "PRS       37768\n",
            "RAINF     36398\n",
            "RH        68658\n",
            "SO2      107752\n",
            "SR        25392\n",
            "TOUT      35885\n",
            "WSR       55915\n",
            "WDR       66289\n",
            "dtype: int64\n",
            "Porcentaje de datos vacíos en TODO2020_2024:\n",
            " date             0.000000\n",
            "CO              13.173512\n",
            "NO              17.221674\n",
            "NO2             17.969367\n",
            "NOX             17.290528\n",
            "O3              16.570285\n",
            "PM10             5.456798\n",
            "PM2.5           24.320213\n",
            "PRS              5.727970\n",
            "RAINF            5.520193\n",
            "RH              10.412809\n",
            "SO2             16.341883\n",
            "SR               3.851001\n",
            "TOUT             5.442390\n",
            "WSR              8.480180\n",
            "WDR             10.053522\n",
            "time             0.000000\n",
            "zona_encoded     0.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# 1.1.2. Cantidad de datos nulos\n",
        "nulos = df_2020_2024.isnull().sum()\n",
        "print(\"\\nCantidad de datos nulos por columna:\")\n",
        "print(nulos[nulos > 0])\n",
        "\n",
        "# Procesar cada dataframe\n",
        "for df, name in zip([df_2020_2024], ['2020_2024']):\n",
        "    # Calcular el porcentaje de valores vacíos o \"NULL\"\n",
        "    null_percentage = df.isnull().mean() * 100\n",
        "    print(f\"Porcentaje de datos vacíos en TODO{name}:\\n\", null_percentage)\n",
        "\n",
        "# df_2020_2021, df_2022_2023, df_2023_2024 son los nombres de los dataframes procesados\n",
        "# 1.1.3. Descripción de las variables\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0Z_4vVeu6p6",
        "outputId": "893a7996-0313-40da-9a2f-963daf58266c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Información de las variables:\n",
            "          Nombre                                        Descripción     Tipo  \\\n",
            "0           date  {'count': 659361, 'unique': 1674, 'top': 2023-...   object   \n",
            "1             CO  {'count': 572500.0, 'mean': 1.3860415772925763...  float64   \n",
            "2             NO  {'count': 545808.0, 'mean': 11.939413383457188...  float64   \n",
            "3            NO2  {'count': 540878.0, 'mean': 14.573269092103954...  float64   \n",
            "4            NOX  {'count': 545354.0, 'mean': 26.287490199026685...  float64   \n",
            "5             O3  {'count': 550103.0, 'mean': 27.020323793907686...  float64   \n",
            "6           PM10  {'count': 623381.0, 'mean': 59.87437008827668,...  float64   \n",
            "7          PM2.5  {'count': 499003.0, 'mean': 20.955216221144966...  float64   \n",
            "8            PRS  {'count': 621593.0, 'mean': 715.1072130799415,...  float64   \n",
            "9          RAINF  {'count': 622963.0, 'mean': 0.0188741706971361...  float64   \n",
            "10            RH  {'count': 590703.0, 'mean': 56.300160283594295...  float64   \n",
            "11           SO2  {'count': 551609.0, 'mean': 4.8394740114827695...  float64   \n",
            "12            SR  {'count': 633969.0, 'mean': -0.288828330722795...  float64   \n",
            "13          TOUT  {'count': 623476.0, 'mean': 23.279450788803405...  float64   \n",
            "14           WSR  {'count': 603446.0, 'mean': 8.590591171372418,...  float64   \n",
            "15           WDR  {'count': 593072.0, 'mean': 136.42364903418135...  float64   \n",
            "16          time  {'count': 659361, 'unique': 24, 'top': 12:00:0...   object   \n",
            "17  zona_encoded  {'count': 659361.0, 'mean': 7.038729921848578,...    int64   \n",
            "\n",
            "    Valores Nulos Valores Posibles  \n",
            "0               0           String  \n",
            "1           86861        Float/Int  \n",
            "2          113553        Float/Int  \n",
            "3          118483        Float/Int  \n",
            "4          114007        Float/Int  \n",
            "5          109258        Float/Int  \n",
            "6           35980        Float/Int  \n",
            "7          160358        Float/Int  \n",
            "8           37768        Float/Int  \n",
            "9           36398        Float/Int  \n",
            "10          68658        Float/Int  \n",
            "11         107752        Float/Int  \n",
            "12          25392        Float/Int  \n",
            "13          35885        Float/Int  \n",
            "14          55915        Float/Int  \n",
            "15          66289        Float/Int  \n",
            "16              0           String  \n",
            "17              0        Float/Int  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "variables_info = []\n",
        "\n",
        "for column in df_2020_2024.columns:\n",
        "    var_info = {\n",
        "        'Nombre': column,\n",
        "        'Descripción': df_2020_2024[column].describe(include='all').to_dict(),\n",
        "        'Tipo': df_2020_2024[column].dtype,\n",
        "        'Valores Nulos': df_2020_2024[column].isnull().sum(),\n",
        "    }\n",
        "\n",
        "    # Solo incluir el tipo de variable para los valores posibles\n",
        "    if isinstance(df_2020_2024[column].dtype, pd.CategoricalDtype) or df_2020_2024[column].dtype == 'object':\n",
        "        var_info['Valores Posibles'] = 'String'\n",
        "    elif pd.api.types.is_numeric_dtype(df_2020_2024[column]):\n",
        "        var_info['Valores Posibles'] = 'Float/Int'\n",
        "    elif pd.api.types.is_datetime64_any_dtype(df_2020_2024[column]):\n",
        "        var_info['Valores Posibles'] = 'Datetime'\n",
        "    else:\n",
        "        var_info['Valores Posibles'] = 'Otro'\n",
        "\n",
        "    variables_info.append(var_info)\n",
        "\n",
        "# Convertir a DataFrame para mejor visualización\n",
        "variables_df = pd.DataFrame(variables_info)\n",
        "\n",
        "# Mostrar el DataFrame con la información de las variables\n",
        "print(\"\\nInformación de las variables:\")\n",
        "print(variables_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "f6sJbSk5ua4Y",
        "outputId": "7570008d-376f-49a3-aa91-a9aed9f3cedc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              date    CO   NO   NO2   NOX    O3    PM10  PM2.5    PRS  RAINF  \\\n",
              "0       2020-01-01   NaN  NaN   NaN   NaN   NaN   86.34  60.91    NaN    NaN   \n",
              "1       2020-01-01   NaN  NaN   6.5   9.8  19.0  112.01  85.64  713.6    0.0   \n",
              "2       2020-01-01   NaN  NaN   5.6   8.8  18.0  100.01  72.39  712.8    0.0   \n",
              "3       2020-01-01  3.22  3.2   7.2  10.4  14.0  106.20  70.25  712.4    0.0   \n",
              "4       2020-01-01  3.26  4.7  10.6  15.3   5.0  141.86  93.72  712.0    0.0   \n",
              "...            ...   ...  ...   ...   ...   ...     ...    ...    ...    ...   \n",
              "659356  2024-07-31  1.18  4.2  11.1  15.2  16.0  117.00  13.73  707.5    0.0   \n",
              "659357  2024-07-31  1.33  4.4  12.5  16.8  13.0   90.00  13.05  707.9    0.0   \n",
              "659358  2024-07-31  1.47  4.6  12.1  16.6  12.0   90.00  12.72  708.4    0.0   \n",
              "659359  2024-07-31  1.26  4.8  11.3  16.0  12.0  104.00  13.63  709.1    0.0   \n",
              "659360  2024-07-31   NaN  NaN   NaN   NaN   NaN     NaN    NaN    NaN    NaN   \n",
              "\n",
              "          RH  SO2     SR   TOUT   WSR    WDR      time  zona_encoded  \n",
              "0        NaN  NaN  0.000    NaN   NaN    NaN  00:00:00             0  \n",
              "1       91.0  NaN  0.158  10.49   3.7    2.0  01:00:00             0  \n",
              "2       91.0  NaN  0.156  10.51   1.9  144.0  02:00:00             0  \n",
              "3       92.0  2.9  0.158  10.64   2.7   28.0  03:00:00             0  \n",
              "4       92.0  3.3  0.163  10.73   2.0   31.0  04:00:00             0  \n",
              "...      ...  ...    ...    ...   ...    ...       ...           ...  \n",
              "659356  46.0  2.8  0.003  29.87  13.1   63.0  19:00:00             6  \n",
              "659357  48.0  2.7  0.000  28.93  11.8   41.0  20:00:00             6  \n",
              "659358  50.0  3.0  0.000  28.31  11.6   41.0  21:00:00             6  \n",
              "659359  58.0  3.0  0.000  27.25  15.3   35.0  22:00:00             6  \n",
              "659360   NaN  NaN    NaN    NaN   NaN    NaN  23:00:00             6  \n",
              "\n",
              "[659361 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b59165ac-5d0e-44fb-8689-31e863679be2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>CO</th>\n",
              "      <th>NO</th>\n",
              "      <th>NO2</th>\n",
              "      <th>NOX</th>\n",
              "      <th>O3</th>\n",
              "      <th>PM10</th>\n",
              "      <th>PM2.5</th>\n",
              "      <th>PRS</th>\n",
              "      <th>RAINF</th>\n",
              "      <th>RH</th>\n",
              "      <th>SO2</th>\n",
              "      <th>SR</th>\n",
              "      <th>TOUT</th>\n",
              "      <th>WSR</th>\n",
              "      <th>WDR</th>\n",
              "      <th>time</th>\n",
              "      <th>zona_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>86.34</td>\n",
              "      <td>60.91</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>00:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.5</td>\n",
              "      <td>9.8</td>\n",
              "      <td>19.0</td>\n",
              "      <td>112.01</td>\n",
              "      <td>85.64</td>\n",
              "      <td>713.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.158</td>\n",
              "      <td>10.49</td>\n",
              "      <td>3.7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>01:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.6</td>\n",
              "      <td>8.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>100.01</td>\n",
              "      <td>72.39</td>\n",
              "      <td>712.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.156</td>\n",
              "      <td>10.51</td>\n",
              "      <td>1.9</td>\n",
              "      <td>144.0</td>\n",
              "      <td>02:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>3.22</td>\n",
              "      <td>3.2</td>\n",
              "      <td>7.2</td>\n",
              "      <td>10.4</td>\n",
              "      <td>14.0</td>\n",
              "      <td>106.20</td>\n",
              "      <td>70.25</td>\n",
              "      <td>712.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>0.158</td>\n",
              "      <td>10.64</td>\n",
              "      <td>2.7</td>\n",
              "      <td>28.0</td>\n",
              "      <td>03:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>3.26</td>\n",
              "      <td>4.7</td>\n",
              "      <td>10.6</td>\n",
              "      <td>15.3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>141.86</td>\n",
              "      <td>93.72</td>\n",
              "      <td>712.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.163</td>\n",
              "      <td>10.73</td>\n",
              "      <td>2.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>04:00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>659356</th>\n",
              "      <td>2024-07-31</td>\n",
              "      <td>1.18</td>\n",
              "      <td>4.2</td>\n",
              "      <td>11.1</td>\n",
              "      <td>15.2</td>\n",
              "      <td>16.0</td>\n",
              "      <td>117.00</td>\n",
              "      <td>13.73</td>\n",
              "      <td>707.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0.003</td>\n",
              "      <td>29.87</td>\n",
              "      <td>13.1</td>\n",
              "      <td>63.0</td>\n",
              "      <td>19:00:00</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>659357</th>\n",
              "      <td>2024-07-31</td>\n",
              "      <td>1.33</td>\n",
              "      <td>4.4</td>\n",
              "      <td>12.5</td>\n",
              "      <td>16.8</td>\n",
              "      <td>13.0</td>\n",
              "      <td>90.00</td>\n",
              "      <td>13.05</td>\n",
              "      <td>707.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.000</td>\n",
              "      <td>28.93</td>\n",
              "      <td>11.8</td>\n",
              "      <td>41.0</td>\n",
              "      <td>20:00:00</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>659358</th>\n",
              "      <td>2024-07-31</td>\n",
              "      <td>1.47</td>\n",
              "      <td>4.6</td>\n",
              "      <td>12.1</td>\n",
              "      <td>16.6</td>\n",
              "      <td>12.0</td>\n",
              "      <td>90.00</td>\n",
              "      <td>12.72</td>\n",
              "      <td>708.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>28.31</td>\n",
              "      <td>11.6</td>\n",
              "      <td>41.0</td>\n",
              "      <td>21:00:00</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>659359</th>\n",
              "      <td>2024-07-31</td>\n",
              "      <td>1.26</td>\n",
              "      <td>4.8</td>\n",
              "      <td>11.3</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>104.00</td>\n",
              "      <td>13.63</td>\n",
              "      <td>709.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>27.25</td>\n",
              "      <td>15.3</td>\n",
              "      <td>35.0</td>\n",
              "      <td>22:00:00</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>659360</th>\n",
              "      <td>2024-07-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23:00:00</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>659361 rows × 18 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b59165ac-5d0e-44fb-8689-31e863679be2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b59165ac-5d0e-44fb-8689-31e863679be2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b59165ac-5d0e-44fb-8689-31e863679be2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e217bbed-fc71-46ac-963a-7566b0b0e405\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e217bbed-fc71-46ac-963a-7566b0b0e405')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e217bbed-fc71-46ac-963a-7566b0b0e405 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_eeabc34c-5761-4390-9e8b-99b3918064a9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eeabc34c-5761-4390-9e8b-99b3918064a9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df_2020_2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skmr9f8vwLq9"
      },
      "source": [
        "#### 1.2.3 Estadistica General"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LklSm6NxwPfL",
        "outputId": "442ed361-4019-4348-d898-1c167f770a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-c22c346ba649>:12: FutureWarning: The provided callable <built-in function min> is currently using Series.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
            "  rango_fechas = df_datetime.agg({'date': [min, max], 'time': [min, max]})\n",
            "<ipython-input-18-c22c346ba649>:12: FutureWarning: The provided callable <built-in function max> is currently using Series.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "  rango_fechas = df_datetime.agg({'date': [min, max], 'time': [min, max]})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rango de la columna 'date' y 'time':\n",
            "          date      time\n",
            "min 2020-01-01  00:00:00\n",
            "max 2024-07-31  23:00:00\n",
            "\n",
            "Estadísticas para columnas numéricas:\n",
            "                  CO             NO            NO2            NOX  \\\n",
            "count  572500.000000  545808.000000  540878.000000  545354.000000   \n",
            "mean        1.386042      11.939413      14.573269      26.287490   \n",
            "std         0.866079      21.930888      17.867913      28.553123   \n",
            "min        -0.130000       0.300000   -9999.000000       0.500000   \n",
            "25%         0.710000       3.100000       6.600000      10.900000   \n",
            "50%         1.260000       5.000000      11.400000      17.400000   \n",
            "75%         1.870000      11.000000      19.400000      30.700000   \n",
            "max        37.000000     945.100000     188.600000     971.800000   \n",
            "\n",
            "                  O3           PM10          PM2.5            PRS  \\\n",
            "count  550103.000000  623381.000000  499003.000000  621593.000000   \n",
            "mean       27.020324      59.874370      20.955216     715.107213   \n",
            "std        18.497419      41.199438      21.243720       9.601169   \n",
            "min         0.700000       2.000000   -9999.000000       0.000000   \n",
            "25%        13.000000      35.000000      11.000000     709.300000   \n",
            "50%        23.000000      51.000000      17.300000     714.200000   \n",
            "75%        37.000000      74.000000      27.000000     721.600000   \n",
            "max       265.000000    1001.000000     999.000000     747.600000   \n",
            "\n",
            "               RAINF             RH            SO2             SR  \\\n",
            "count  622963.000000  590703.000000  551609.000000  633969.000000   \n",
            "mean        0.018874      56.300160       4.839474      -0.288828   \n",
            "std         1.065691      46.482986       4.485952      66.454052   \n",
            "min         0.000000   -9999.000000       0.000000   -9999.000000   \n",
            "25%         0.000000      40.000000       2.800000       0.000000   \n",
            "50%         0.000000      58.000000       3.700000       0.007000   \n",
            "75%         0.000000      74.000000       5.500000       0.251000   \n",
            "max       360.000000     714.200000     295.100000     501.000000   \n",
            "\n",
            "                TOUT            WSR            WDR   zona_encoded  \n",
            "count  623476.000000  603446.000000  593072.000000  659361.000000  \n",
            "mean       23.279451       8.590591     136.423649       7.038730  \n",
            "std        14.796481       6.824093      95.818960       4.398848  \n",
            "min     -9999.000000       0.100000   -9999.000000       0.000000  \n",
            "25%        18.550000       4.300000      73.000000       3.000000  \n",
            "50%        24.000000       7.500000     113.000000       7.000000  \n",
            "75%        28.440000      11.600000     174.000000      11.000000  \n",
            "max       112.390000     227.100000     360.000000      14.000000  \n",
            "\n",
            "Medidas de tendencia central y dispersión:\n",
            "\n",
            "Media:\n",
            "CO                1.386042\n",
            "NO               11.939413\n",
            "NO2              14.573269\n",
            "NOX              26.287490\n",
            "O3               27.020324\n",
            "PM10             59.874370\n",
            "PM2.5            20.955216\n",
            "PRS             715.107213\n",
            "RAINF             0.018874\n",
            "RH               56.300160\n",
            "SO2               4.839474\n",
            "SR               -0.288828\n",
            "TOUT             23.279451\n",
            "WSR               8.590591\n",
            "WDR             136.423649\n",
            "zona_encoded      7.038730\n",
            "dtype: float64\n",
            "\n",
            "Mediana:\n",
            "CO                1.260\n",
            "NO                5.000\n",
            "NO2              11.400\n",
            "NOX              17.400\n",
            "O3               23.000\n",
            "PM10             51.000\n",
            "PM2.5            17.300\n",
            "PRS             714.200\n",
            "RAINF             0.000\n",
            "RH               58.000\n",
            "SO2               3.700\n",
            "SR                0.007\n",
            "TOUT             24.000\n",
            "WSR               7.500\n",
            "WDR             113.000\n",
            "zona_encoded      7.000\n",
            "dtype: float64\n",
            "\n",
            "Moda:\n",
            "CO                0.59\n",
            "NO                2.70\n",
            "NO2               0.50\n",
            "NOX               0.50\n",
            "O3               16.00\n",
            "PM10             43.00\n",
            "PM2.5            12.00\n",
            "PRS             728.00\n",
            "RAINF             0.00\n",
            "RH               77.00\n",
            "SO2               2.60\n",
            "SR                0.00\n",
            "TOUT             25.30\n",
            "WSR               1.40\n",
            "WDR             105.00\n",
            "zona_encoded      3.00\n",
            "Name: 0, dtype: float64\n",
            "\n",
            "Varianza:\n",
            "CO                 0.750092\n",
            "NO               480.963854\n",
            "NO2              319.262327\n",
            "NOX              815.280835\n",
            "O3               342.154523\n",
            "PM10            1697.393660\n",
            "PM2.5            451.295628\n",
            "PRS               92.182454\n",
            "RAINF              1.135697\n",
            "RH              2160.668026\n",
            "SO2               20.123767\n",
            "SR              4416.141045\n",
            "TOUT             218.935847\n",
            "WSR               46.568239\n",
            "WDR             9181.273068\n",
            "zona_encoded      19.349866\n",
            "dtype: float64\n",
            "\n",
            "Desviación estándar:\n",
            "CO               0.866079\n",
            "NO              21.930888\n",
            "NO2             17.867913\n",
            "NOX             28.553123\n",
            "O3              18.497419\n",
            "PM10            41.199438\n",
            "PM2.5           21.243720\n",
            "PRS              9.601169\n",
            "RAINF            1.065691\n",
            "RH              46.482986\n",
            "SO2              4.485952\n",
            "SR              66.454052\n",
            "TOUT            14.796481\n",
            "WSR              6.824093\n",
            "WDR             95.818960\n",
            "zona_encoded     4.398848\n",
            "dtype: float64\n",
            "\n",
            "Rango:\n",
            "CO                 37.13\n",
            "NO                944.80\n",
            "NO2             10187.60\n",
            "NOX               971.30\n",
            "O3                264.30\n",
            "PM10              999.00\n",
            "PM2.5           10998.00\n",
            "PRS               747.60\n",
            "RAINF             360.00\n",
            "RH              10713.20\n",
            "SO2               295.10\n",
            "SR              10500.00\n",
            "TOUT            10111.39\n",
            "WSR               227.00\n",
            "WDR             10359.00\n",
            "zona_encoded       14.00\n",
            "dtype: float64\n",
            "\n",
            "Cuartiles:\n",
            "        CO    NO   NO2   NOX    O3  PM10  PM2.5    PRS  RAINF    RH  SO2  \\\n",
            "0.25  0.71   3.1   6.6  10.9  13.0  35.0   11.0  709.3    0.0  40.0  2.8   \n",
            "0.50  1.26   5.0  11.4  17.4  23.0  51.0   17.3  714.2    0.0  58.0  3.7   \n",
            "0.75  1.87  11.0  19.4  30.7  37.0  74.0   27.0  721.6    0.0  74.0  5.5   \n",
            "\n",
            "         SR   TOUT   WSR    WDR  zona_encoded  \n",
            "0.25  0.000  18.55   4.3   73.0           3.0  \n",
            "0.50  0.007  24.00   7.5  113.0           7.0  \n",
            "0.75  0.251  28.44  11.6  174.0          11.0  \n"
          ]
        }
      ],
      "source": [
        "# Filtrar las columnas 'date' y 'time' en un nuevo dataframe\n",
        "df_datetime = df_2020_2024[['date', 'time']].copy()\n",
        "\n",
        "# Convertir la columna 'date' al formato datetime en df_datetime\n",
        "df_datetime['date'] = pd.to_datetime(df_datetime['date'])\n",
        "\n",
        "# Convertir la columna 'time' al formato datetime (sin fecha) para extraer la hora\n",
        "# Ajustar el formato a '%H:%M:%S' si incluye segundos\n",
        "df_datetime['time'] = pd.to_datetime(df_datetime['time'], format='%H:%M:%S', errors='coerce').dt.time\n",
        "\n",
        "# Mostrar el rango (mínimo y máximo) para la columna 'date' y la columna 'time'\n",
        "rango_fechas = df_datetime.agg({'date': [min, max], 'time': [min, max]})\n",
        "\n",
        "# Estadísticas para columnas numéricas (excluyendo datetime)\n",
        "df_numerico = df_2020_2024.select_dtypes(include=[np.number])\n",
        "estadisticas_numericas = df_numerico.describe()\n",
        "\n",
        "# Medidas de tendencia central y dispersión para columnas numéricas\n",
        "tendencia_central = {\n",
        "    'media': df_numerico.mean(),\n",
        "    'mediana': df_numerico.median(),\n",
        "    'moda': df_numerico.mode().iloc[0],  # La primera moda en caso de varias\n",
        "    'varianza': df_numerico.var(),\n",
        "    'desviación estándar': df_numerico.std(),\n",
        "    'rango': df_numerico.max() - df_numerico.min()\n",
        "}\n",
        "\n",
        "# Medidas de posición no-central (cuartiles)\n",
        "cuartiles = df_numerico.quantile([0.25, 0.5, 0.75])\n",
        "\n",
        "# Impresión del rango de la columna 'date' y 'time'\n",
        "print(\"Rango de la columna 'date' y 'time':\")\n",
        "print(rango_fechas)\n",
        "\n",
        "# Impresión de las estadísticas numéricas\n",
        "print(\"\\nEstadísticas para columnas numéricas:\")\n",
        "print(estadisticas_numericas)\n",
        "\n",
        "print(\"\\nMedidas de tendencia central y dispersión:\")\n",
        "for key, value in tendencia_central.items():\n",
        "    print(f\"\\n{key.capitalize()}:\\n{value}\")\n",
        "\n",
        "print(\"\\nCuartiles:\")\n",
        "print(cuartiles)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mSpmIGG5QEv"
      },
      "source": [
        "1.2.3. Calidad de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwQxU4vzuogx"
      },
      "source": [
        "Esto fue realizado obteniendo la cantidad de outliers dentro de cada variable\n",
        "\n",
        "**¿Qué se hizo con los outliers?**\n",
        "En el siguiente codigo, los valores que sean determinados como outliers, seran determinados como valores NaN, para posteriormente ser imputados mediente el algoritmo MICE,  esto con la intencion de no perder infromación que podrian representar, al igual que permitir una mejor normalización de la información."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVeqHx2kYsxD",
        "outputId": "0766cd9b-527b-4259-a2e8-de7a426bd40c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe con outliers reemplazados por NaN:\n",
            "              date    CO   NO   NO2   NOX    O3    PM10  PM2.5    PRS  RAINF  \\\n",
            "0       2020-01-01   NaN  NaN   NaN   NaN   NaN   86.34    NaN    NaN    NaN   \n",
            "1       2020-01-01   NaN  NaN   6.5   9.8  19.0  112.01    NaN  713.6    0.0   \n",
            "2       2020-01-01   NaN  NaN   5.6   8.8  18.0  100.01    NaN  712.8    0.0   \n",
            "3       2020-01-01  3.22  3.2   7.2  10.4  14.0  106.20    NaN  712.4    0.0   \n",
            "4       2020-01-01  3.26  4.7  10.6  15.3   5.0     NaN    NaN  712.0    0.0   \n",
            "...            ...   ...  ...   ...   ...   ...     ...    ...    ...    ...   \n",
            "659356  2024-07-31  1.18  4.2  11.1  15.2  16.0  117.00  13.73  707.5    0.0   \n",
            "659357  2024-07-31  1.33  4.4  12.5  16.8  13.0   90.00  13.05  707.9    0.0   \n",
            "659358  2024-07-31  1.47  4.6  12.1  16.6  12.0   90.00  12.72  708.4    0.0   \n",
            "659359  2024-07-31  1.26  4.8  11.3  16.0  12.0  104.00  13.63  709.1    0.0   \n",
            "659360  2024-07-31   NaN  NaN   NaN   NaN   NaN     NaN    NaN    NaN    NaN   \n",
            "\n",
            "          RH  SO2     SR   TOUT   WSR    WDR      time  zona_encoded  \n",
            "0        NaN  NaN  0.000    NaN   NaN    NaN  00:00:00             0  \n",
            "1       91.0  NaN  0.158  10.49   3.7    2.0  01:00:00             0  \n",
            "2       91.0  NaN  0.156  10.51   1.9  144.0  02:00:00             0  \n",
            "3       92.0  2.9  0.158  10.64   2.7   28.0  03:00:00             0  \n",
            "4       92.0  3.3  0.163  10.73   2.0   31.0  04:00:00             0  \n",
            "...      ...  ...    ...    ...   ...    ...       ...           ...  \n",
            "659356  46.0  2.8  0.003  29.87  13.1   63.0  19:00:00             6  \n",
            "659357  48.0  2.7  0.000  28.93  11.8   41.0  20:00:00             6  \n",
            "659358  50.0  3.0  0.000  28.31  11.6   41.0  21:00:00             6  \n",
            "659359  58.0  3.0  0.000  27.25  15.3   35.0  22:00:00             6  \n",
            "659360   NaN  NaN    NaN    NaN   NaN    NaN  23:00:00             6  \n",
            "\n",
            "[659361 rows x 18 columns]\n",
            "\n",
            "Cantidad de outliers reemplazados por columna:\n",
            "CO: 9656 outliers\n",
            "NO: 65266 outliers\n",
            "NO2: 22002 outliers\n",
            "NOX: 45087 outliers\n",
            "O3: 13008 outliers\n",
            "PM10: 28205 outliers\n",
            "PM2.5: 19279 outliers\n",
            "PRS: 2919 outliers\n",
            "RAINF: 7930 outliers\n",
            "RH: 15 outliers\n",
            "SO2: 40060 outliers\n",
            "SR: 36255 outliers\n",
            "TOUT: 3795 outliers\n",
            "WSR: 9718 outliers\n",
            "WDR: 30623 outliers\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Función para eliminar los outliers usando el rango intercuartílico (IQR)\n",
        "def eliminar_outliers(col):\n",
        "    Q1 = col.quantile(0.25)\n",
        "    Q3 = col.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Contar outliers\n",
        "    outliers_count = ((col < lower_bound) | (col > upper_bound)).sum()\n",
        "\n",
        "    # Reemplazar outliers por NaN\n",
        "    col_cleaned = col.where((col >= lower_bound) & (col <= upper_bound))\n",
        "\n",
        "    return col_cleaned, outliers_count\n",
        "\n",
        "# Inicializar un DataFrame para almacenar la cantidad de outliers\n",
        "outliers_info = {}\n",
        "\n",
        "# Aplicar la función para eliminar outliers en las columnas relevantes\n",
        "for col in columnas_relevantes:\n",
        "    df_2020_2024[col], count = eliminar_outliers(df_2020_2024[col])\n",
        "    outliers_info[col] = count\n",
        "\n",
        "# Mostrar resultados, asegurando que se mantengan las columnas 'date', 'time', y 'Zona_encoded'\n",
        "print(\"Dataframe con outliers reemplazados por NaN:\")\n",
        "print(df_2020_2024)\n",
        "\n",
        "# Mostrar la cantidad de outliers por columna\n",
        "print(\"\\nCantidad de outliers reemplazados por columna:\")\n",
        "for column, count in outliers_info.items():\n",
        "    print(f\"{column}: {count} outliers\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Medidas de posición no-central (cuartiles)\n",
        "cuartiles = df_numerico.quantile([0.25, 0.5, 0.75])\n",
        "\n",
        "# Visualización de los datos numéricos\n",
        "df_numerico.hist(bins=20, figsize=(14, 10))\n",
        "plt.suptitle('Histogramas de variables numéricas')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "0infzVGV5qG-",
        "outputId": "0261645f-7d99-4d4a-d0b3-13e543edd735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_numerico' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-97924463c983>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Medidas de posición no-central (cuartiles)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcuartiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_numerico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Visualización de los datos numéricos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_numerico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_numerico' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdf_numerico.plot(kind='box', subplots=True, layout=(6,4 ), figsize=(18, 30), sharex=False, sharey=False)\n",
        "plt.suptitle('Boxplots de variables numéricas')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "Xdy8lUsy6CQG",
        "outputId": "10a9c2a7-f180-45cb-bbb3-72c40d00f681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'rdf_numerico' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3fa87921a719>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrdf_numerico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'box'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Boxplots de variables numéricas'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rdf_numerico' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Análisis de correlación y mapa de calor\n",
        "correlacion = df_numerico.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlacion, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Mapa de calor de correlación')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J3Fsatf86De4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laH68FQ4omF8"
      },
      "source": [
        "## Imputacion de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QyBt3fUvmMc"
      },
      "source": [
        "Utilizando el algoritmo MICE, de la biblioteca *fancyimput*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFQlMjJR_W80"
      },
      "outputs": [],
      "source": [
        "!pip install fancyimpute\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_2020_2024"
      ],
      "metadata": {
        "id": "2Jejsa-bq9wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAVTVd0IUclM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fancyimpute import IterativeImputer  # MICE implementation in fancyimpute\n",
        "\n",
        "# Preprocesamiento de los datos\n",
        "df_2020_2024['date'] = pd.to_datetime(df_2020_2024['date'])\n",
        "df_2020_2024.set_index('date', inplace=True)\n",
        "df_2020_2024.sort_index(inplace=True)\n",
        "\n",
        "# Convertir a formato numérico las columnas relevantes (importante para imputar correctamente)\n",
        "df_2020_2024_numeric = df_2020_2024.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Mantener la columna \"Zona\" separada\n",
        "df_zona = df_2020_2024[['zona_encoded']]  # Guarda la columna 'Zona'\n",
        "\n",
        "# Seleccionar las columnas relevantes para la imputación (las numéricas)\n",
        "variables_para_imputar = df_2020_2024_numeric[['CO', 'NO', 'NO2', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2', 'WSR' ,\t'WDR']]  # Añade más columnas si es necesario\n",
        "\n",
        "# Aplicar el algoritmo MICE para imputación\n",
        "mice_imputer = IterativeImputer()  # Por defecto usa regresión bayesiana iterativa (JUSTIFICAR)\n",
        "df_imputed_mice = mice_imputer.fit_transform(variables_para_imputar)\n",
        "\n",
        "# Convertir de nuevo a dataframe para mantener el formato original\n",
        "df_imputed_mice = pd.DataFrame(df_imputed_mice, columns=variables_para_imputar.columns, index=variables_para_imputar.index)\n",
        "\n",
        "# Reintegrar la columna \"Zona\" al DataFrame imputado\n",
        "df_final = pd.concat([df_imputed_mice, df_zona], axis=1)\n",
        "\n",
        "# Mostrar el DataFrame final\n",
        "print(df_final)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ejemplo de tu DataFrame, df_UBI\n",
        "\n",
        "# Diccionario de encoding de las zonas\n",
        "zona_dict = {\n",
        "    'CENTRO': 0,\n",
        "    'NORESTE': 1,\n",
        "    'NORESTE2': 2,\n",
        "    'NORESTE3': 3,\n",
        "    'NOROESTE': 4,\n",
        "    'NOROESTE2': 5,\n",
        "    'NOROESTE3': 6,\n",
        "    'NORTE': 7,\n",
        "    'NORTE2': 8,\n",
        "    'SUR': 9,\n",
        "    'SURESTE': 10,\n",
        "    'SURESTE2': 11,\n",
        "    'SURESTE3': 12,\n",
        "    'SUROESTE': 13,\n",
        "    'SUROESTE2': 14,\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# 1. Reemplazar la columna 'Zona' con los valores del diccionario\n",
        "df_UBI['Zona'] = df_UBI['Zona'].map(zona_dict)\n",
        "\n",
        "# 2. Separar la columna 'location' en 'latitud' y 'longitud'\n",
        "df_UBI[['latitud', 'longitud']] = df_UBI['location'].str.split(',', expand=True)\n",
        "\n",
        "# 3. Convertir 'latitud' y 'longitud' en formato numérico\n",
        "df_UBI['latitud'] = pd.to_numeric(df_UBI['latitud'])\n",
        "df_UBI['longitud'] = pd.to_numeric(df_UBI['longitud'])\n",
        "\n",
        "# 4. Eliminar la columna original 'location' si ya no es necesaria\n",
        "df_UBI = df_UBI.drop(columns=['location'])\n",
        "\n",
        "# Mostrar el DataFrame actualizado\n",
        "#print(df_UBI)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Asegúrate de que la columna 'date' ya no sea un índice\n",
        "df_final = df_final.reset_index()  # 'date' vuelve a ser una columna\n",
        "\n",
        "# Separar la columna 'date' en 'date' y 'time'\n",
        "df_final['date'] = pd.to_datetime(df_final['date'])  # Convertir a formato datetime si no lo está\n",
        "df_final['time'] = df_final['date'].dt.time  # Extraer la hora\n",
        "df_final['date'] = df_final['date'].dt.date  # Extraer solo la fecha\n",
        "\n",
        "# Unir los dataframes usando la columna 'zona_encoded' como clave\n",
        "df_completo = df_final.merge(df_UBI, left_on='zona_encoded', right_on='Zona')\n",
        "\n",
        "# Opcional: Si quieres que 'date' vuelva a ser el índice después del merge\n",
        "# df_completo = df_completo.set_index('date')\n",
        "\n",
        "# Mostrar el DataFrame actualizado\n",
        "print(df_completo)\n",
        "\n"
      ],
      "metadata": {
        "id": "m6UZfMY1DMXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import contextily as ctx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.interpolate import griddata\n",
        "from pyproj import Transformer\n",
        "\n",
        "# Asegúrate de que las columnas 'date' y 'time' estén en el formato adecuado\n",
        "df_completo['date'] = pd.to_datetime(df_completo['date']).dt.date  # Solo la fecha\n",
        "#df_completo['time'] = pd.to_datetime(df_completo['time']).dt.time  # Solo la hora\n",
        "\n",
        "# Fecha y hora específicas para filtrar\n",
        "fecha_especifica = '2024-07-31'\n",
        "hora_especifica = '23:00:00'\n",
        "\n",
        "# Filtrar los datos por fecha y hora separadas\n",
        "df_filtrado = df_completo[(df_completo['date'].astype(str) == fecha_especifica) &\n",
        "                          (df_completo['time'].astype(str) == hora_especifica)]\n",
        "\n",
        "# Agrupar por Zona para calcular las concentraciones promedio de CO, WSR, WDR para esa fecha/hora\n",
        "coords_zonas = df_filtrado.groupby('Zona').agg({\n",
        "    'latitud': 'mean',\n",
        "    'longitud': 'mean',\n",
        "    'CO': 'mean',\n",
        "    'WSR': 'mean',\n",
        "    'WDR': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Crear un GeoDataFrame con las coordenadas de las zonas\n",
        "gdf_zonas = gpd.GeoDataFrame(\n",
        "    coords_zonas,\n",
        "    geometry=gpd.points_from_xy(coords_zonas['longitud'], coords_zonas['latitud']),\n",
        "    crs=\"EPSG:4326\"  # Sistema de coordenadas WGS 84\n",
        ")\n",
        "\n",
        "# Transformar a un sistema de coordenadas proyectadas adecuado para añadir el mapa base\n",
        "gdf_zonas = gdf_zonas.to_crs(epsg=3857)  # Proyección Web Mercator (compatible con contextily)\n",
        "\n",
        "# Crear una malla de puntos para la interpolación\n",
        "lon_grid, lat_grid = np.mgrid[\n",
        "    coords_zonas['longitud'].min():coords_zonas['longitud'].max():100j,\n",
        "    coords_zonas['latitud'].min():coords_zonas['latitud'].max():100j\n",
        "]\n",
        "\n",
        "# Realizar la interpolación\n",
        "interpolated_CO = griddata(\n",
        "    (coords_zonas['longitud'], coords_zonas['latitud']),\n",
        "    coords_zonas['CO'],\n",
        "    (lon_grid, lat_grid),\n",
        "    method='cubic'\n",
        ")\n",
        "\n",
        "# Ajustar la interpolación de CO según la velocidad del viento\n",
        "interpolated_CO_adjusted = interpolated_CO * (1 + coords_zonas['WSR'].mean() / max(coords_zonas['WSR']))\n",
        "\n",
        "# Crear un transformador para convertir de WGS84 (EPSG:4326) a Web Mercator (EPSG:3857)\n",
        "transformer = Transformer.from_crs(\"epsg:4326\", \"epsg:3857\", always_xy=True)\n",
        "\n",
        "# Transformar las coordenadas de la malla\n",
        "lon_grid_proj, lat_grid_proj = transformer.transform(lon_grid, lat_grid)\n",
        "\n",
        "# Crear el mapa base\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "# Graficar las estaciones\n",
        "gdf_zonas.plot(ax=ax, color='black', markersize=100, label='Estaciones')\n",
        "\n",
        "# Añadir el mapa base de contexto con contextily\n",
        "ctx.add_basemap(ax, crs=gdf_zonas.crs, source=ctx.providers.OpenStreetMap.Mapnik)\n",
        "\n",
        "# Graficar el mapa de calor utilizando las coordenadas proyectadas\n",
        "contour = ax.contourf(lon_grid_proj, lat_grid_proj, interpolated_CO_adjusted, cmap='coolwarm', alpha=0.6)\n",
        "\n",
        "# Agregar una barra de colores\n",
        "cbar = fig.colorbar(contour, ax=ax, label='Concentración CO ajustada')\n",
        "\n",
        "# Añadir título y etiquetas\n",
        "plt.title(f'Distribución de CO ajustada por viento en {fecha_especifica} {hora_especifica}', fontsize=15)\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a_XMH17kDOoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2020_2024"
      ],
      "metadata": {
        "id": "S0PaspJvqLK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_imputed_mice"
      ],
      "metadata": {
        "id": "F8mJWsvqqFwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4lWsc-oWgYT"
      },
      "outputs": [],
      "source": [
        "# Graficar los resultados antes y después de la imputación para una columna, por ejemplo 'CO'\n",
        "plt.plot(df_2020_2024['CO'], label='CO Original')\n",
        "plt.plot(df_imputed_mice['CO'], label='CO Imputado (MICE)', linestyle='--', alpha = 0.5)\n",
        "plt.legend()\n",
        " # Rango para el eje X\n",
        "plt.ylim([-30, 180])\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpaknN3Exc16"
      },
      "outputs": [],
      "source": [
        "df_imputed_mice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjK1gm_GlwvM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Supongamos que df_sin_outliers ya está definido y contiene las columnas de interés\n",
        "\n",
        "# Seleccionar las columnas a estandarizar\n",
        "columns_to_standardize = ['CO', 'NO', 'NO2', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2']\n",
        "\n",
        "# Estandarización (Media 0, Desviación Estándar 1)\n",
        "scaler = StandardScaler()\n",
        "df_standardized = df_imputed_mice.copy()  # Hacer una copia para no modificar el original\n",
        "df_standardized[columns_to_standardize] = scaler.fit_transform(df_imputed_mice[columns_to_standardize])\n",
        "\n",
        "# Graficar la distribución estandarizada\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, column in enumerate(columns_to_standardize, 1):\n",
        "    plt.subplot(4, 2, i)  # Cambié a 4 filas y 2 columnas para adaptarse a 8 columnas\n",
        "    sns.kdeplot(df_standardized[column].dropna(), fill=True)  # Cambiado 'shade=True' por 'fill=True'\n",
        "    plt.title(f\"Distribución Estandarizada: {column}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Distribución Estandarizada sin Outliers por Columna\", fontsize=16)\n",
        "plt.subplots_adjust(top=0.9)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j23rXL9z7-9"
      },
      "source": [
        "## 3. Transformacion de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO9QXsBpz-RE"
      },
      "source": [
        "Se busca desarrollar un modelo que analice las tendencias en la aparición de smog.\n",
        "\n",
        "Dado el alto tráfico y la naturaleza industrial de Monterrey, se han considerado las siguientes variables:\n",
        "\n",
        "**NOx (Óxidos de nitrógeno)**\n",
        "\n",
        "Razón: Incluye tanto NO como NO2 y es fundamental en la formación de ozono troposférico, un contaminante secundario que afecta la salud y la calidad del aire. Además, contribuye a la formación de PM2.5.\n",
        "Fuentes: Principalmente proviene del tráfico vehicular y de actividades industriales.\n",
        "\n",
        "**CO (Monóxido de carbono)**\n",
        "\n",
        "Razón: Es un contaminante significativo en áreas urbanas, especialmente por el tráfico. Aunque su impacto inmediato en la salud se manifiesta a concentraciones muy altas, también está asociado con problemas respiratorios a largo plazo. Fuentes: Se origina principalmente por la combustión incompleta en vehículos y sistemas de calefacción.\n",
        "\n",
        "**O3 (Ozono troposférico)**\n",
        "\n",
        "Razón: Aunque no se emite directamente, se forma a partir de otros contaminantes (como NOx y compuestos orgánicos volátiles) en presencia de luz solar. Es un irritante respiratorio y puede causar problemas de salud.\n",
        "Condiciones: Se convierte en un problema especialmente en días soleados y cálidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEBKXjR-z-g1"
      },
      "source": [
        "**Discretizacion de los datos (binning)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXXUm-pF31mm"
      },
      "source": [
        "La discretización puede llevarse a cabo siguiendo las directrices del PRCA,. A partir de ello, se puede crear un conjunto de variables categóricas que, tras nuestro análisis, permitirá desarrollar un sistema de semaforización que indique el riesgo o la probabilidad de aparición de smog. Las moléculas consideradas en el PRCA incluyen PM10, PM2.5, O3, CO, SO2 y NO2.\n",
        "\n",
        "Es importante destacar que el smog fotoquímico se forma en un entorno urbano por la coexistencia de reactivos y productos, específicamente cuando están presentes óxidos de nitrógeno (NOx), monóxido de carbono (CO) y otros compuestos orgánicos volátiles (COVs) en combinación con la radiación solar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FyDL_6o0CEk"
      },
      "source": [
        "**Escalamiento y normalizacion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMMY4ycG5dJH"
      },
      "source": [
        "Se llevó a cabo un escalado y estandarización de los datos debido a las diferencias significativas entre los valores. Este proceso facilita un análisis más sencillo y coherente, permitiendo que todos los datos sean comparados sobre una misma base."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O2BhoAG0EOd"
      },
      "source": [
        "**Construccion de atributos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiTZgIrg6G7A"
      },
      "source": [
        "En este caso, se recomienda abordar el análisis de dos maneras:\n",
        "\n",
        "Muchos contaminantes son el resultado de otros. Por ejemplo, el NOx se compone de NO y NO2, y el ozono se forma a partir del NOx.\n",
        "\\\n",
        "\\\n",
        "Al trabajar con datos temporales, se pueden agrupar por meses, estaciones y horarios, lo que permite realizar comparaciones entre períodos de alta actividad, como las horas pico y las vacaciones.\n",
        "\n",
        "Por el momento, nos enfocaremos en las variables que representan moléculas, ya que aquellas que dependen de condiciones ambientales tienden a tener un comportamiento inestable.\n",
        "\n",
        "Variables a considerar: ['CO', 'NO', 'NO2', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYqetuRO5oL_"
      },
      "source": [
        "### Adelanto preeliminar, matriz de correlaciones entre variables."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seleccionar las columnas de interés\n",
        "columns_of_interest = ['CO', 'NO', 'NO2', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2']\n",
        "df_selected = df_2020_2024[columns_of_interest]\n",
        "\n",
        "# Reiniciar el índice del dataframe\n",
        "df_selected.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Graficar boxplots\n",
        "plt.figure(figsize=(15, 10))\n",
        "# Usar un boxplot para cada contaminante\n",
        "for i, column in enumerate(columns_of_interest):\n",
        "    plt.subplot(3, 3, i + 1)  # Crear una tabla de 3 filas y 3 columnas\n",
        "    sns.boxplot(y=df_selected[column])\n",
        "    plt.title(f'Boxplot de {column}')\n",
        "    plt.xlabel('')\n",
        "\n",
        "plt.tight_layout()  # Ajustar el espaciado entre los subplots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Kf41HSBPHjhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrDI1Il56e8g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_2020_2024\n",
        "\n",
        "# Seleccionar las columnas de interés\n",
        "columns_of_interest = ['CO', 'NO', 'NO2', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2']\n",
        "df_selected = df_2020_2024[columns_of_interest]\n",
        "\n",
        "# Calcular la matriz de correlación\n",
        "correlation_matrix = df_selected.corr()\n",
        "\n",
        "# Graficar la matriz de correlación usando un mapa de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\",\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .8})\n",
        "plt.title(\"Matriz de Correlaciones entre Contaminantes\", fontsize=16)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R8n5x6f82Tj"
      },
      "source": [
        "## ¿Que se desea realizar?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICUo_fC98-W4"
      },
      "source": [
        "Un modelo que logre ilustrar el comportamiento y aparición del smog sobre el\n",
        "\n",
        "1.   Elemento de lista\n",
        "2.   Elemento de lista\n",
        "\n",
        "area metropolitana de Nuevo Leon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZjLn0S6848r"
      },
      "source": [
        "## ¿Qué variables se van a utilizar?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu9cSo-e9JtO"
      },
      "source": [
        "['CO', 'NO', 'NO2', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndkSuq3XBvVZ"
      },
      "outputs": [],
      "source": [
        "#df_2020_2024.to_csv('/content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/PROCESADO/TODO/BASE_A_USAR_2020_2024.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Investigacion"
      ],
      "metadata": {
        "id": "eM5jmQG-nZhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataframes a utilizar"
      ],
      "metadata": {
        "id": "0E3oYZQynbKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ubicaciones\n",
        "#df_UBI = pd.read_csv('/content/gdrive/MyDrive/SIMA/BASES_DE_DATOS/PROCESADO/UBICACIONES/UBI.csv')\n",
        "df_UBI\n",
        "#Contaminantes\n",
        "df_final"
      ],
      "metadata": {
        "id": "t0G_bhXCndHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_UBI"
      ],
      "metadata": {
        "id": "PqGT1uUsnwkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ejemplo de tu DataFrame, df_UBI\n",
        "\n",
        "# Diccionario de encoding de las zonas\n",
        "zona_dict = {\n",
        "    'CENTRO': 0,\n",
        "    'NORESTE': 1,\n",
        "    'NORESTE2': 2,\n",
        "    'NORESTE3': 3,\n",
        "    'NOROESTE': 4,\n",
        "    'NOROESTE2': 5,\n",
        "    'NOROESTE3': 6,\n",
        "    'NORTE': 7,\n",
        "    'NORTE2': 8,\n",
        "    'SUR': 9,\n",
        "    'SURESTE': 10,\n",
        "    'SURESTE2': 11,\n",
        "    'SURESTE3': 12,\n",
        "    'SUROESTE': 13,\n",
        "    'SUROESTE2': 14,\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# 1. Reemplazar la columna 'Zona' con los valores del diccionario\n",
        "df_UBI['Zona'] = df_UBI['Zona'].map(zona_dict)\n",
        "\n",
        "# 2. Separar la columna 'location' en 'latitud' y 'longitud'\n",
        "df_UBI[['latitud', 'longitud']] = df_UBI['location'].str.split(',', expand=True)\n",
        "\n",
        "# 3. Convertir 'latitud' y 'longitud' en formato numérico\n",
        "df_UBI['latitud'] = pd.to_numeric(df_UBI['latitud'])\n",
        "df_UBI['longitud'] = pd.to_numeric(df_UBI['longitud'])\n",
        "\n",
        "# 4. Eliminar la columna original 'location' si ya no es necesaria\n",
        "df_UBI = df_UBI.drop(columns=['location'])\n",
        "\n",
        "# Mostrar el DataFrame actualizado\n",
        "print(df_UBI)\n"
      ],
      "metadata": {
        "id": "DOhzQInSoei4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final"
      ],
      "metadata": {
        "id": "8RFGegLcruiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from geopy.distance import geodesic\n",
        "import numpy as np\n",
        "\n",
        "# Crear una función para calcular la distancia entre dos estaciones\n",
        "def calcular_distancia(coord1, coord2):\n",
        "    return geodesic(coord1, coord2).kilometers\n",
        "\n",
        "# Crear una matriz vacía para las distancias\n",
        "n = len(df_UBI)\n",
        "distancias = np.zeros((n, n))\n",
        "\n",
        "# Calcular las distancias entre todas las estaciones\n",
        "for i in range(n):\n",
        "    for j in range(n):\n",
        "        coord1 = (df_UBI.iloc[i]['latitud'], df_UBI.iloc[i]['longitud'])\n",
        "        coord2 = (df_UBI.iloc[j]['latitud'], df_UBI.iloc[j]['longitud'])\n",
        "        distancias[i, j] = calcular_distancia(coord1, coord2)\n",
        "\n",
        "# Convertir la matriz en un DataFrame para mejor legibilidad\n",
        "df_distancias = pd.DataFrame(distancias, index=df_UBI['Clave_Estacion'], columns=df_UBI['Clave_Estacion'])\n",
        "\n",
        "# Mostrar la matriz de distancias\n",
        "print(df_distancias)\n"
      ],
      "metadata": {
        "id": "WLTNiwG-slZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unir los dataframes usando la columna 'zona_encoded' como clave\n",
        "df_completo = df_final.merge(df_UBI, left_on='zona_encoded', right_on='Zona')\n",
        "\n",
        "# Seleccionar solo las columnas de contaminantes y ubicación geográfica\n",
        "contaminantes_y_coords = df_completo[['CO', 'NO', 'NO2', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2', 'latitud', 'longitud']]\n"
      ],
      "metadata": {
        "id": "v-fzFlKetOsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Normalizar los datos (importante para clustering en datos con escalas diferentes)\n",
        "scaler = StandardScaler()\n",
        "datos_normalizados = scaler.fit_transform(contaminantes_y_coords)\n",
        "\n",
        "# Aplicar KMeans para agrupar las estaciones\n",
        "n_clusters = 4  # Ajusta este valor según lo que quieras explorar\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "df_completo['cluster'] = kmeans.fit_predict(datos_normalizados)\n"
      ],
      "metadata": {
        "id": "jSqzprcwtgJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convertir el DataFrame a un GeoDataFrame\n",
        "gdf = gpd.GeoDataFrame(df_completo,\n",
        "                        geometry=gpd.points_from_xy(df_completo['longitud'], df_completo['latitud']))\n",
        "\n",
        "# Lista de contaminantes para los que se creará un mapa\n",
        "contaminantes = ['CO', 'NO', 'NO2', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2']\n",
        "\n",
        "# Crear un mapa para cada contaminante\n",
        "for contaminante in contaminantes:\n",
        "    # Normalizar los datos del contaminante específico\n",
        "    scaler = StandardScaler()\n",
        "    contaminante_normalizado = scaler.fit_transform(gdf[[contaminante]])\n",
        "\n",
        "    # Aplicar KMeans para agrupar las estaciones por contaminante\n",
        "    n_clusters = 4  # Ajusta este valor según lo que quieras explorar\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "    gdf[f'cluster_{contaminante}'] = kmeans.fit_predict(contaminante_normalizado)\n",
        "\n",
        "    # Configuración de colores para los clusters\n",
        "    colores = ['red', 'blue', 'green', 'purple']\n",
        "\n",
        "    # Crear la figura del mapa\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "    # Dibujar las estaciones con los colores de los clusters\n",
        "    gdf.plot(column=f'cluster_{contaminante}',\n",
        "             cmap='Set1',\n",
        "             ax=ax,\n",
        "             legend=True,\n",
        "             legend_kwds={'label': \"Clusters\",\n",
        "                          'orientation': \"horizontal\"},\n",
        "             markersize=100)\n",
        "\n",
        "    # Añadir título y etiquetas\n",
        "    ax.set_title(f'Mapa de Clusters para {contaminante}')\n",
        "    ax.set_xlabel('Longitud')\n",
        "    ax.set_ylabel('Latitud')\n",
        "\n",
        "    # Mostrar el mapa\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "_OFZzTpAthyQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}